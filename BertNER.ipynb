{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "513fc6d3ad763b04"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:22.125253Z",
     "start_time": "2024-04-23T17:36:22.107255Z"
    }
   },
   "id": "fbe45218338bb909",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Installing libraries required"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd6a76f94bd8fa1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quibb\\code\\cse4095\\venv\\lib\\site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:27.799214Z",
     "start_time": "2024-04-23T17:36:22.233286Z"
    }
   },
   "id": "ce3d8899a4114cfb",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:49.059451Z",
     "start_time": "2024-04-23T17:37:49.046417Z"
    }
   },
   "id": "90b3ce25005a117",
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Load the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "272b033b6d0ca239"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "url_train='https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio'\n",
    "url_test='https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:27.814933Z",
     "start_time": "2024-04-23T17:36:27.800893Z"
    }
   },
   "id": "4044ffcaa71e6b56",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import wget\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:27.830930Z",
     "start_time": "2024-04-23T17:36:27.815931Z"
    }
   },
   "id": "ecb3ded7e143db43",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'engtrain (4).bio'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(url_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.195272Z",
     "start_time": "2024-04-23T17:36:27.832920Z"
    }
   },
   "id": "55631dcf9cd6e090",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'engtest (2).bio'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(url_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.476778Z",
     "start_time": "2024-04-23T17:36:28.197241Z"
    }
   },
   "id": "21e52a535be4d72",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We must append all the rows from the bio format file using the csvreader().**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62d05baf8e31edd7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "tokens = []\n",
    "token_labels = []\n",
    "unique_labels = set()\n",
    "\n",
    "with open(\"./engtrain.bio\", newline = '') as lines:                                                                                          \n",
    "  \n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    for line in line_reader:\n",
    "        \n",
    "        if line == []:\n",
    "\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "\n",
    "            unique_labels.add(line[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.571089Z",
     "start_time": "2024-04-23T17:36:28.478744Z"
    }
   },
   "id": "b79c4a27b7f7bab7",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what movies star bruce willis\n",
      "show me films with drew barrymore from the 1980s\n",
      "what movies starred both al pacino and robert deniro\n",
      "find me all of the movies that starred harold ramis and bill murray\n",
      "find me a movie with a quote about baseball in it\n",
      "what movies have mississippi in the title\n",
      "show me science fiction films directed by steven spielberg\n",
      "do you have any thrillers directed by sofia coppola\n",
      "what leonard cohen songs have been used in a movie\n",
      "show me films elvis films set in hawaii\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check output\n",
    "[  print(' '.join(sentences[i])) for i in range(10)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.586764Z",
     "start_time": "2024-04-23T17:36:28.572742Z"
    }
   },
   "id": "524ee78efc2d9731",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Preprocessing the data\n",
    "- Preparing input text data for Feeding it into BERT model by converting and splitting the text into tokens and mapping the tokens using BertTokenizer functon"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2bb6c6ab9fe3cba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.682740Z",
     "start_time": "2024-04-23T17:36:28.587765Z"
    }
   },
   "id": "52681d8ed67a5d77",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sentences[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.698774Z",
     "start_time": "2024-04-23T17:36:28.683738Z"
    }
   },
   "id": "c3bc4b02091bd416",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'[CLS] show me films with drew [UNK] from the 1980s [SEP]'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:28.714740Z",
     "start_time": "2024-04-23T17:36:28.701737Z"
    }
   },
   "id": "57e61a8a8fe90fe7",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the length of the tokenized sentences\n",
    "TokenLength=[len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:31.131737Z",
     "start_time": "2024-04-23T17:36:28.716741Z"
    }
   },
   "id": "81c8d392a84fafa0",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum  length: 3 tokens\n",
      "Maximum length: 51 tokens\n",
      "Median length: 12 tokens\n"
     ]
    }
   ],
   "source": [
    "# Check the length of the tokenized sentences\n",
    "print('Minimum  length: {:,} tokens'.format(min(TokenLength)))\n",
    "print('Maximum length: {:,} tokens'.format(max(TokenLength)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(TokenLength))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:31.147775Z",
     "start_time": "2024-04-23T17:36:31.134738Z"
    }
   },
   "id": "d48f9c8ef8785852",
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Now we must include Padding [PAD] token in the input so every tokens should be of same length. We have selected max length of PAD token to be 55 (as max is 51)**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ace0c4dd49d2ead2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample Sentence\n",
    "SampleSentence=tokenizer.encode_plus(' '.join(sentences[1]), add_special_tokens = True,truncation = True,max_length = 50,padding = True,return_attention_mask = True, return_tensors = 'pt')\n",
    "SampleSentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:31.162736Z",
     "start_time": "2024-04-23T17:36:31.149737Z"
    }
   },
   "id": "a92de5839f8f10c2",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Ids: tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]])\n",
      "\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Input_ids\n",
    "print(\"\\nInput Ids:\",SampleSentence[\"input_ids\"])\n",
    "# Attention_mask\n",
    "print(\"\\nAttention Mask:\",SampleSentence[\"attention_mask\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:31.177742Z",
     "start_time": "2024-04-23T17:36:31.165738Z"
    }
   },
   "id": "c6c1a2344ccc6680",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Mapping Label\n",
    "label_map = {}\n",
    "\n",
    "for (i, label) in enumerate(unique_labels):\n",
    "    \n",
    "    # Map it to its integer\n",
    "    label_map[label] = i"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:31.193740Z",
     "start_time": "2024-04-23T17:36:31.178741Z"
    }
   },
   "id": "2c04117a4847f0f4",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['find', 'the', 'movies', 'action', 'movies', 'directed', 'by', 'john', 'woo', 'from', 'the', '1990s']\n",
      "Token IDs: tensor([  101,  2424,  1996,  5691,  2895,  5691,  2856,  2011,  2198, 15854,\n",
      "         2013,  1996,  4134,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Adding Attention Mask\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                 \n",
    "                        add_special_tokens = True,\n",
    "                        truncation = True,\n",
    "                        max_length = 55,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "        \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "print('Original: ', sentences[24])\n",
    "print('Token IDs:', input_ids[24])\n",
    "print('Masks:', attention_masks[24])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:34.757383Z",
     "start_time": "2024-04-23T17:36:31.195742Z"
    }
   },
   "id": "976e3ab440282d31",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['what', 'movies', 'starred', 'both', 'al', 'pacino', 'and', 'robert', 'deniro']\n",
      "\n",
      "Labels:       ['O', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR', 'O', 'B-ACTOR', 'I-ACTOR']\n",
      "\n",
      "BERT Tokens:  ['what', 'movies', 'starred', 'both', 'al', 'pac', '##ino', 'and', 'robert', 'den', '##iro']\n",
      "\n",
      "Token IDs:    tensor([  101,  2054,  5691,  5652,  2119,  2632, 14397,  5740,  1998,  2728,\n",
      "         7939,  9711,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "\n",
      "New Labels:   [-100, 7, 7, 7, 7, 14, 24, -100, 7, 14, 24, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    for token_id in sen:\n",
    "\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    new_labels.append(padded_labels)\n",
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:37.512386Z",
     "start_time": "2024-04-23T17:36:34.758384Z"
    }
   },
   "id": "4e70fa9e2347da4a",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert the lists into PyTorch tensors using torch.stack() function**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70ce5a1f28c4d8d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Concatenates a sequence of tensors along a new dimension\n",
    "# [7,660  x  50].\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:37.575765Z",
     "start_time": "2024-04-23T17:36:37.513385Z"
    }
   },
   "id": "f6aa8175b3b94917",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,797 training samples\n",
      "  978 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:37.591420Z",
     "start_time": "2024-04-23T17:36:37.577388Z"
    }
   },
   "id": "8bc110e8d1afcafe",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Convert tensors into Batches for batch wise training and using RandomSampler for selecting the batch Randomly**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "246e5d396465175b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
    "\n",
    "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size   )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:36:37.607385Z",
     "start_time": "2024-04-23T17:36:37.593387Z"
    }
   },
   "id": "d9d0b73d25063bd1",
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Using 12 Layer BERT model for output task**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0e67fdaedd7a9e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertForTokenClassification, AdamW, BertConfig\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m BertForTokenClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbert-base-uncased\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(label_map) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, output_attentions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, output_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:2567\u001B[0m, in \u001B[0;36mPreTrainedModel.cuda\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2562\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2563\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCalling `cuda()` is not supported for `4-bit` or `8-bit` quantized models. Please use the model as it is, since the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2564\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2565\u001B[0m     )\n\u001B[0;32m   2566\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcuda(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:911\u001B[0m, in \u001B[0;36mModule.cuda\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m    894\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    895\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    896\u001B[0m \n\u001B[0;32m    897\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    909\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 911\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    821\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    823\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 825\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    826\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:911\u001B[0m, in \u001B[0;36mModule.cuda.<locals>.<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    894\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcuda\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, device: Optional[Union[\u001B[38;5;28mint\u001B[39m, device]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m    895\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001B[39;00m\n\u001B[0;32m    896\u001B[0m \n\u001B[0;32m    897\u001B[0m \u001B[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    909\u001B[0m \u001B[38;5;124;03m        Module: self\u001B[39;00m\n\u001B[0;32m    910\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 911\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(\u001B[38;5;28;01mlambda\u001B[39;00m t: \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\code\\CSE4095\\venv\\lib\\site-packages\\torch\\cuda\\__init__.py:293\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    289\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    290\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    291\u001B[0m     )\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 293\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    297\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(label_map) + 1, output_attentions = False, output_hidden_states = False)\n",
    "\n",
    "\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:57.344341Z",
     "start_time": "2024-04-23T17:37:56.910346Z"
    }
   },
   "id": "b15b7c83277b3295",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9f219be31cdd14b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
