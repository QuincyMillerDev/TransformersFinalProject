{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "colab": {
   "name": "BERT Named Entity Recognition-Part 2.ipynb",
   "provenance": []
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "6a041dc95d004cb58e9c6ab35a8f775e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_fbc255790ed645d2b9bbbe34a0f41fb4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e0d1ca2f558d437d90ee539d4aa7d967",
       "IPY_MODEL_4cb113d4cce749529b400becb7800e9a"
      ]
     }
    },
    "fbc255790ed645d2b9bbbe34a0f41fb4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e0d1ca2f558d437d90ee539d4aa7d967": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_e6c77b6b00c8481d9373c1b232af6d70",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 231508,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 231508,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7c476f22442747cf9183adf6ec04e684"
     }
    },
    "4cb113d4cce749529b400becb7800e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a29928124a8b434d9dadd9145a9b700f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 232k/232k [00:00&lt;00:00, 801kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_955bbe594f494b0b8b5f8b0d680a7de8"
     }
    },
    "e6c77b6b00c8481d9373c1b232af6d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7c476f22442747cf9183adf6ec04e684": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a29928124a8b434d9dadd9145a9b700f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "955bbe594f494b0b8b5f8b0d680a7de8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f0f78f547a9a487f9fb75eb867a93884": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_cff24be995c94fc089719a3cd60f1a72",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_482813ec8bb74312bb252fea9c40e7eb",
       "IPY_MODEL_51bf070093c44a6681639ae2fdb2e335"
      ]
     }
    },
    "cff24be995c94fc089719a3cd60f1a72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "482813ec8bb74312bb252fea9c40e7eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_06c0d6655faf41a2ace2372773746aee",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 433,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 433,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_16b9169fbff84e1e93b48f3b28823335"
     }
    },
    "51bf070093c44a6681639ae2fdb2e335": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_19992285488741579699790689a7fc97",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 433/433 [00:06&lt;00:00, 66.9B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c6989f206b6c4cbdb5c1c1fb3e7ac2ac"
     }
    },
    "06c0d6655faf41a2ace2372773746aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "16b9169fbff84e1e93b48f3b28823335": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "19992285488741579699790689a7fc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c6989f206b6c4cbdb5c1c1fb3e7ac2ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6bceb14ea46a4a3895c28d79a4585e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_0ca9f3ea8b3c42fa8b86c38bafdde679",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_71595cbecf9241f8802c408b521362c4",
       "IPY_MODEL_136701faefcd4b099f4a12465159d076"
      ]
     }
    },
    "0ca9f3ea8b3c42fa8b86c38bafdde679": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "71595cbecf9241f8802c408b521362c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_806e889dba514f798ff1119cf2710908",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 440473133,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 440473133,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_b008247aa1cf415a98d782c1b9832c83"
     }
    },
    "136701faefcd4b099f4a12465159d076": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_9c04b67acf2846ab9946dd9c8b177e14",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 440M/440M [00:06&lt;00:00, 73.1MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6bbe3d657b8741f4987bc3da35b37e4c"
     }
    },
    "806e889dba514f798ff1119cf2710908": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "b008247aa1cf415a98d782c1b9832c83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9c04b67acf2846ab9946dd9c8b177e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6bbe3d657b8741f4987bc3da35b37e4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "EinYpeWGGRx5",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:31.565442Z",
     "start_time": "2024-04-23T18:02:25.913634Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcPjfkCju6V_"
   },
   "source": [
    "**Checking the Availability of GPU in the colab Notebook using cuda library and instructing it to use GPU for processing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81tgqOMqGRyG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "961cca9c-e803-463d-809f-598bb29428d7",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:31.581442Z",
     "start_time": "2024-04-23T18:02:31.569444Z"
    }
   },
   "source": [
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print( torch.cuda.device_count())\n",
    "    print('Available:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgQK1YjCvj6K"
   },
   "source": [
    "**Installing the required libraries required**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "romEHhWyGRyK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6863eea1-ee99-457a-d897-f9d985676f70",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:48.796151Z",
     "start_time": "2024-04-23T18:02:31.582440Z"
    }
   },
   "source": [
    "!pip install wget\n",
    "!pip install transformers"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/09/c8/844d5518a6aeb4ffdc0cf0cae65ae13dbe5838306728c5c640b5a6e2a0c9/transformers-4.40.0-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.19.3 from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/e0/63/c8e3c0956581df6349126d5f3821077a89032ae99520961d9be7cde68865/regex-2024.4.16-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/f4/85/d999b9a05fd101d48f1a365d68be0b109277bb25c89fb37a389d669f9185/tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/28/78/82c03572b085b658d24a13ae0ae4779c0712a167af6c313d39ee5b5e7f73/safetensors-0.4.3-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.4.3-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Obtaining dependency information for tqdm>=4.27 from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quibb\\code\\cse4095\\transformersfinalproject\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "   ---------------------------------------- 0.0/9.0 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.7/9.0 MB 36.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.9/9.0 MB 52.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.0/9.0 MB 63.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.0/9.0 MB 52.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "   ---------------------------------------- 0.0/388.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 388.9/388.9 kB 25.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp310-cp310-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.9/268.9 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp310-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.4/287.4 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 71.3 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.22.2 regex-2024.4.16 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.2 transformers-4.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEOcvHhJvtbs"
   },
   "source": [
    "**Downloading the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dO56hpaDGRyN",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:48.811143Z",
     "start_time": "2024-04-23T18:02:48.799149Z"
    }
   },
   "source": [
    "url_train='https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio'\n",
    "url_test='https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio'\n"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gjPc27BCGRyQ",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:48.826179Z",
     "start_time": "2024-04-23T18:02:48.813147Z"
    }
   },
   "source": [
    "import wget\n",
    "import os"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Hf97iYwGRyS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "3cf5fe28-fbce-49e9-807e-eab210007b31",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:49.216132Z",
     "start_time": "2024-04-23T18:02:48.827177Z"
    }
   },
   "source": [
    "wget.download(url_train)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'engtrain.bio'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uIjIrttBGRyX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "14012e22-3716-4173-cd15-c97ca38338ad",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:49.463716Z",
     "start_time": "2024-04-23T18:02:49.218101Z"
    }
   },
   "source": [
    "wget.download(url_test)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'engtest.bio'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo6xBZdevyJC"
   },
   "source": [
    "**Appending all the row lines from bio format file using csvreader() function**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2gSAx8Y5GRya",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:49.572762Z",
     "start_time": "2024-04-23T18:02:49.464714Z"
    }
   },
   "source": [
    "import csv\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "tokens = []\n",
    "token_labels = []\n",
    "unique_labels = set()\n",
    "\n",
    "with open(\"./engtrain.bio\", newline = '') as lines:                                                                                          \n",
    "  \n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    for line in line_reader:\n",
    "        \n",
    "        if line == []:\n",
    "\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "\n",
    "            unique_labels.add(line[0])\n",
    "\n",
    "            "
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_qKmwL70x-"
   },
   "source": [
    "**Sentences Output**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WC65g2rytJ7",
    "outputId": "ad2b67fd-22d9-4d66-da72-b32609c3070b",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:49.588747Z",
     "start_time": "2024-04-23T18:02:49.574711Z"
    }
   },
   "source": [
    "\n",
    "[  print(' '.join(sentences[i])) for i in range(10)]"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what movies star bruce willis\n",
      "show me films with drew barrymore from the 1980s\n",
      "what movies starred both al pacino and robert deniro\n",
      "find me all of the movies that starred harold ramis and bill murray\n",
      "find me a movie with a quote about baseball in it\n",
      "what movies have mississippi in the title\n",
      "show me science fiction films directed by steven spielberg\n",
      "do you have any thrillers directed by sofia coppola\n",
      "what leonard cohen songs have been used in a movie\n",
      "show me films elvis films set in hawaii\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDg8hjB52u_J"
   },
   "source": [
    "**Preparing input text data for Feeding it into BERT model by converting and spilting the text into tokens and mapping the tokens using BertTokenizer functon**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOwSlC_23y0W",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6a041dc95d004cb58e9c6ab35a8f775e",
      "fbc255790ed645d2b9bbbe34a0f41fb4",
      "e0d1ca2f558d437d90ee539d4aa7d967",
      "4cb113d4cce749529b400becb7800e9a",
      "e6c77b6b00c8481d9373c1b232af6d70",
      "7c476f22442747cf9183adf6ec04e684",
      "a29928124a8b434d9dadd9145a9b700f",
      "955bbe594f494b0b8b5f8b0d680a7de8"
     ]
    },
    "outputId": "b66b8b23-7db7-4334-c93b-42d86596074e",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:50.423409Z",
     "start_time": "2024-04-23T18:02:49.592749Z"
    }
   },
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gha2W9-T4rVx",
    "outputId": "fc0f8e7d-4cd2-474c-bf74-9ca7b011ebc7",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:50.439086Z",
     "start_time": "2024-04-23T18:02:50.425088Z"
    }
   },
   "source": [
    "tokenizer.encode(sentences[1])"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lvqEe3-44YWL",
    "outputId": "029bb5b7-a1b5-4089-9a02-754c9680fdab",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:50.455135Z",
     "start_time": "2024-04-23T18:02:50.440122Z"
    }
   },
   "source": [
    "tokenizer.decode([101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102])"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'[CLS] show me films with drew [UNK] from the 1980s [SEP]'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVU9xXifAJuM"
   },
   "source": [
    "**Calculating of length of each tokenized sentences**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FYUoces5_Df9",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:53.118489Z",
     "start_time": "2024-04-23T18:02:50.456122Z"
    }
   },
   "source": [
    "TokenLength=[len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZD9Ze4YRGRys",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1762dfdf-277e-41f2-db45-53c3f601eb23",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:53.134443Z",
     "start_time": "2024-04-23T18:02:53.121485Z"
    }
   },
   "source": [
    "print('Minimum  length: {:,} tokens'.format(min(TokenLength)))\n",
    "print('Maximum length: {:,} tokens'.format(max(TokenLength)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(TokenLength))))"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum  length: 3 tokens\n",
      "Maximum length: 51 tokens\n",
      "Median length: 12 tokens\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv1-fXOPIF3P"
   },
   "source": [
    "**Now we must include Padding [PAD] token in the input so every tokens should be of same length. We have selected max length of PAD token to be 55 (as max is 51)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RvwHU9UKPDB",
    "outputId": "8db1b587-adfd-4293-812f-dccef092d6b5",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:53.181478Z",
     "start_time": "2024-04-23T18:02:53.136445Z"
    }
   },
   "source": [
    "#Sample Sentence\n",
    "SampleSentence=tokenizer.encode_plus(' '.join(sentences[1]), add_special_tokens = True,truncation = True,max_length = 50,padding = True,return_attention_mask = True, return_tensors = 'pt')\n",
    "SampleSentence"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CECUpOILCFg",
    "outputId": "11f57a41-648a-4add-93b0-136b3e809317",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:53.197474Z",
     "start_time": "2024-04-23T18:02:53.183452Z"
    }
   },
   "source": [
    "##input_ids\n",
    "print(\"\\nInput Ids:\",SampleSentence[\"input_ids\"])\n",
    "##attention_mask\n",
    "print(\"\\nAttention Mask:\",SampleSentence[\"attention_mask\"])"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Ids: tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]])\n",
      "\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xh5TO6kyw7S"
   },
   "source": [
    "**Mapping Label**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7BbOt-rfdlQT",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:53.213441Z",
     "start_time": "2024-04-23T18:02:53.198485Z"
    }
   },
   "source": [
    "label_map = {}\n",
    "\n",
    "for (i, label) in enumerate(unique_labels):\n",
    "    \n",
    "    # Map it to its integer\n",
    "    label_map[label] = i"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3jld86Gg6lb"
   },
   "source": [
    "**Adding Attention Mask**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mqtli4ItGRy5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "11dba3c6-7d66-48a5-aaa7-332ce41733c7",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:57.186020Z",
     "start_time": "2024-04-23T18:02:53.215439Z"
    }
   },
   "source": [
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                 \n",
    "                        add_special_tokens = True,\n",
    "                        truncation = True,\n",
    "                        max_length = 55,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "        \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "print('Original: ', sentences[24])\n",
    "print('Token IDs:', input_ids[24])\n",
    "print('Masks:', attention_masks[24])"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['find', 'the', 'movies', 'action', 'movies', 'directed', 'by', 'john', 'woo', 'from', 'the', '1990s']\n",
      "Token IDs: tensor([  101,  2424,  1996,  5691,  2895,  5691,  2856,  2011,  2198, 15854,\n",
      "         2013,  1996,  4134,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rEq3NzfJGRy8",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:02:59.993409Z",
     "start_time": "2024-04-23T18:02:57.187654Z"
    }
   },
   "source": [
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    for token_id in sen:\n",
    "\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    new_labels.append(padded_labels)\n"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J7Yb2HxHGRy-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7bdfe24-1df4-45fb-d395-b896c768a55b",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:00.009051Z",
     "start_time": "2024-04-23T18:02:59.996055Z"
    }
   },
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['what', 'movies', 'starred', 'both', 'al', 'pacino', 'and', 'robert', 'deniro']\n",
      "\n",
      "Labels:       ['O', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR', 'O', 'B-ACTOR', 'I-ACTOR']\n",
      "\n",
      "BERT Tokens:  ['what', 'movies', 'starred', 'both', 'al', 'pac', '##ino', 'and', 'robert', 'den', '##iro']\n",
      "\n",
      "Token IDs:    tensor([  101,  2054,  5691,  5652,  2119,  2632, 14397,  5740,  1998,  2728,\n",
      "         7939,  9711,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "\n",
      "New Labels:   [-100, 0, 0, 0, 0, 10, 21, -100, 0, 10, 21, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJTXY7VC8EWz"
   },
   "source": [
    "**Convert the lists into PyTorch tensors using torch.stack**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "56ffz1wIGRzH",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:00.102052Z",
     "start_time": "2024-04-23T18:03:00.012055Z"
    }
   },
   "source": [
    "\n",
    "# Concatenates a sequence of tensors along a new dimension\n",
    "# [7,660  x  50].\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mEXnbx2qGRzP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bba222e3-d234-4296-b59f-e1d3ca1d6944",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:00.118086Z",
     "start_time": "2024-04-23T18:03:00.103053Z"
    }
   },
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,797 training samples\n",
      "  978 validation samples\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0_CkFFJmBlN"
   },
   "source": [
    "**Convert tensors into Batches for batch wise training and using RandomSampler for selecting the batch Randomly**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kl2f3rA6GRzU",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:00.134054Z",
     "start_time": "2024-04-23T18:03:00.119087Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
    "\n",
    "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size   )"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yg7McKZmgim"
   },
   "source": [
    "**Using 12 Layer BERT Model for out task**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PYYvsMS2GRzb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f0f78f547a9a487f9fb75eb867a93884",
      "cff24be995c94fc089719a3cd60f1a72",
      "482813ec8bb74312bb252fea9c40e7eb",
      "51bf070093c44a6681639ae2fdb2e335",
      "06c0d6655faf41a2ace2372773746aee",
      "16b9169fbff84e1e93b48f3b28823335",
      "19992285488741579699790689a7fc97",
      "c6989f206b6c4cbdb5c1c1fb3e7ac2ac",
      "6bceb14ea46a4a3895c28d79a4585e99",
      "0ca9f3ea8b3c42fa8b86c38bafdde679",
      "71595cbecf9241f8802c408b521362c4",
      "136701faefcd4b099f4a12465159d076",
      "806e889dba514f798ff1119cf2710908",
      "b008247aa1cf415a98d782c1b9832c83",
      "9c04b67acf2846ab9946dd9c8b177e14",
      "6bbe3d657b8741f4987bc3da35b37e4c"
     ]
    },
    "outputId": "c5990ab9-80cb-4b63-9867-66f4148d8c09",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:01.475118Z",
     "start_time": "2024-04-23T18:03:00.151054Z"
    }
   },
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(label_map) + 1, output_attentions = False, output_hidden_states = False)\n",
    "\n",
    "\n",
    "model.to('cpu')"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=26, bias=True)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VOE8XK4UGRzf",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:02.741796Z",
     "start_time": "2024-04-23T18:03:01.477081Z"
    }
   },
   "source": [
    "# Load the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon \n",
    "                )\n"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IaC7TvxnGRzh",
    "ExecuteTime": {
     "end_time": "2024-04-23T18:03:02.757467Z",
     "start_time": "2024-04-23T18:03:02.743437Z"
    }
   },
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-VdS40_3GRzl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1af9a35-2e1b-42c1-caa1-cd2e509c9888",
    "ExecuteTime": {
     "end_time": "2024-04-23T19:38:33.413362Z",
     "start_time": "2024-04-23T18:03:02.765432Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "       \n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.43\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.17\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.13\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.10\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsSXxx9oGPZ"
   },
   "source": [
    "**Preparing the Test dataset same as training dataset for predicting the results of our Trained model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w7_TcEDNKsWw",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:35.275634Z",
     "start_time": "2024-04-23T20:19:35.231597Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "# List of all sentences in the dataset.\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Lists to store the current sentence.\n",
    "tokens = []\n",
    "token_labels = []\n",
    "unique_labels = set()\n",
    "\n",
    "with open(\"./engtest.bio\", newline = '') as lines:                                                                                          \n",
    "    \n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    for line in line_reader:\n",
    "        \n",
    "        if line == []:\n",
    "\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "            unique_labels.add(line[0])"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rbtkP2ASKsgi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1cd49ef0-2c52-4214-a104-493588d82442",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:36.541288Z",
     "start_time": "2024-04-23T20:19:35.352609Z"
    }
   },
   "source": [
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(sent_str,add_special_tokens = True, max_length = 50,pad_to_max_length = True, return_attention_mask = True, return_tensors = 'pt')\n",
    "       \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Masks:', attention_masks[0])"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['are', 'there', 'any', 'good', 'romantic', 'comedies', 'out', 'right', 'now']\n",
      "Token IDs: tensor([  101,  2024,  2045,  2151,  2204,  6298, 22092,  2041,  2157,  2085,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "93XGGErfKsjv",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:37.769799Z",
     "start_time": "2024-04-23T20:19:36.543289Z"
    }
   },
   "source": [
    "new_labels = []\n",
    "\n",
    "null_label_id = -100\n",
    "\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    for token_id in sen:\n",
    "        \n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    new_labels.append(padded_labels)\n"
   ],
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JTGNzTeXKsmz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d851cb2f-29db-442d-b264-fea7a7380a07",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:37.784799Z",
     "start_time": "2024-04-23T20:19:37.770798Z"
    }
   },
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nMask:        ', attention_masks[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['list', 'the', 'five', 'star', 'rated', 'movies', 'starring', 'mel', 'gibson']\n",
      "\n",
      "Labels:       ['O', 'O', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR']\n",
      "\n",
      "BERT Tokens:  ['list', 'the', 'five', 'star', 'rated', 'movies', 'starring', 'mel', 'gibson']\n",
      "\n",
      "Token IDs:    tensor([  101,  2862,  1996,  2274,  2732,  6758,  5691,  4626, 11463,  9406,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "\n",
      "New Labels:   [-100, 0, 0, 5, 2, 0, 0, 0, 10, 21, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a7SzPapJLOyg",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:37.843797Z",
     "start_time": "2024-04-23T20:19:37.787794Z"
    }
   },
   "source": [
    "\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NppBuk1QLdiO",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:19:37.879796Z",
     "start_time": "2024-04-23T20:19:37.856797Z"
    }
   },
   "source": [
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkNAIgwXo4DZ"
   },
   "source": [
    "**Prediction on test set**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "785gLPxdLO1S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99c04c58-39be-4e78-8492-52211b376b76",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:21:29.986900Z",
     "start_time": "2024-04-23T20:19:37.882797Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,443 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zE4mSq9TLO4F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ee07be09-03d6-48db-d086-6bc557c9ded3",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:21:30.033892Z",
     "start_time": "2024-04-23T20:21:29.988894Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening the batches, the predictions have shape:\n",
      "     (2443, 50, 26)\n",
      "\n",
      "After choosing the highest scoring label for each token:\n",
      "     (2443, 50)\n",
      "\n",
      "After flattening the sentences, we have predictions:\n",
      "     (122150,)\n",
      "and ground truth:\n",
      "     (122150,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uAdgtvbvLope",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1fc8625f-de18-4368-d5e8-f6a176090c31",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:21:30.094894Z",
     "start_time": "2024-04-23T20:21:30.035895Z"
    }
   },
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))\n"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out `null` tokens, length = 122,150\n",
      " After filtering out `null` tokens, length = 24,686\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q-awFd4kLosC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1d384a4-e6ff-497b-f7c3-8665f94cbb40",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:21:30.170900Z",
     "start_time": "2024-04-23T20:21:30.096894Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(real_token_labels, real_token_predictions, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 94.47%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evga9CGCeSG5"
   },
   "source": [
    "# **Testing the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cz7xJngdzlc",
    "outputId": "c74b8315-5eb0-4d44-f0ff-2670b4e5e6e0",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:24:00.367910Z",
     "start_time": "2024-04-23T20:23:58.420853Z"
    }
   },
   "source": [
    "test_sentence = input (\"Type a sentence:\") "
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUXjwTfovbcy"
   },
   "source": [
    "## ***Checking the Results*** "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XdHIKtw0bHgx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "outputId": "2852982c-5344-4722-ace3-cb3e801cbde8",
    "ExecuteTime": {
     "end_time": "2024-04-23T20:24:02.085905Z",
     "start_time": "2024-04-23T20:24:01.988935Z"
    }
   },
   "source": [
    "\n",
    "#Encoding and convert the sentences into tensors\n",
    "sample_sentence = tokenizer.encode(test_sentence)\n",
    "sample_input_ids = torch.tensor([sample_sentence]).to('cpu')\n",
    "\n",
    "#Predicting the test data set using model() function\n",
    "with torch.no_grad():\n",
    "    output = model(sample_input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "#Function which retrieves key value for our Label Dictionary\n",
    "def get_key(val):\n",
    "    for key, value in label_map.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "#Tokenize  \n",
    "tokens = tokenizer.convert_ids_to_tokens(sample_input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_label = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_label.append(get_key(label_idx))\n",
    "        new_tokens.append(token)\n",
    "\n",
    "#Appending Tokens and Labels\n",
    "movie_token=[]\n",
    "movie_label=[]\n",
    "for token, label in zip(new_tokens, new_label):\n",
    "    movie_token.append(token) \n",
    "    movie_label.append(label)\n",
    "\n",
    "df=pd.DataFrame({\"Token\":movie_token,\"Movie_Label\":movie_label})\n",
    "df.T"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "                0              1   2    3    4   5            6  7        8   \\\nToken        [CLS]  characterized  by  its  use  of  technicolor  ,  fantasy   \nMovie_Label      O              O   O    O    O   O            O  O  B-GENRE   \n\n                       9   ...       44       45       46 47    48        49  \\\nToken        storytelling  ...     with      the     wind  ,  also  directed   \nMovie_Label             O  ...  I-TITLE  I-TITLE  I-TITLE  O     O         O   \n\n             50          51 52     53  \nToken        by     fleming  .  [SEP]  \nMovie_Label   O  I-DIRECTOR  O      O  \n\n[2 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Token</th>\n      <td>[CLS]</td>\n      <td>characterized</td>\n      <td>by</td>\n      <td>its</td>\n      <td>use</td>\n      <td>of</td>\n      <td>technicolor</td>\n      <td>,</td>\n      <td>fantasy</td>\n      <td>storytelling</td>\n      <td>...</td>\n      <td>with</td>\n      <td>the</td>\n      <td>wind</td>\n      <td>,</td>\n      <td>also</td>\n      <td>directed</td>\n      <td>by</td>\n      <td>fleming</td>\n      <td>.</td>\n      <td>[SEP]</td>\n    </tr>\n    <tr>\n      <th>Movie_Label</th>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>B-GENRE</td>\n      <td>O</td>\n      <td>...</td>\n      <td>I-TITLE</td>\n      <td>I-TITLE</td>\n      <td>I-TITLE</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>I-DIRECTOR</td>\n      <td>O</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Conclusion**\n",
    "\n",
    "Results Interpretation:\n",
    "The provided result table displays tokens from the sentence and their corresponding entity labels. For example:\n",
    "\n",
    "- \"fantasy\" is labeled as B-GENRE indicating the beginning of a genre entity.\n",
    "- \"storytelling\" follows without a genre label, suggesting it's not part of a recognized entity under the genre category.\n",
    "- \"american\" is tagged as B-PLOT, marking the beginning of a plot-related entity.\n",
    "- The movie \"Gone with the Wind\" is recognized with B-TITLE, I-TITLE, I-TITLE, I-TITLE labels indicating each part of the title.\n",
    "- \"fleming\" is labeled as I-DIRECTOR, identifying it as part of a director's name.\n",
    "- This kind of model is useful for extracting structured information from unstructured text, such as identifying key components in movie descriptions or reviews."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
