{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "colab": {
   "name": "BERT Named Entity Recognition-Part 2.ipynb",
   "provenance": []
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "6a041dc95d004cb58e9c6ab35a8f775e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_fbc255790ed645d2b9bbbe34a0f41fb4",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_e0d1ca2f558d437d90ee539d4aa7d967",
       "IPY_MODEL_4cb113d4cce749529b400becb7800e9a"
      ]
     }
    },
    "fbc255790ed645d2b9bbbe34a0f41fb4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e0d1ca2f558d437d90ee539d4aa7d967": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_e6c77b6b00c8481d9373c1b232af6d70",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 231508,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 231508,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_7c476f22442747cf9183adf6ec04e684"
     }
    },
    "4cb113d4cce749529b400becb7800e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_a29928124a8b434d9dadd9145a9b700f",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 232k/232k [00:00&lt;00:00, 801kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_955bbe594f494b0b8b5f8b0d680a7de8"
     }
    },
    "e6c77b6b00c8481d9373c1b232af6d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "7c476f22442747cf9183adf6ec04e684": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "a29928124a8b434d9dadd9145a9b700f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "955bbe594f494b0b8b5f8b0d680a7de8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "f0f78f547a9a487f9fb75eb867a93884": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_cff24be995c94fc089719a3cd60f1a72",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_482813ec8bb74312bb252fea9c40e7eb",
       "IPY_MODEL_51bf070093c44a6681639ae2fdb2e335"
      ]
     }
    },
    "cff24be995c94fc089719a3cd60f1a72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "482813ec8bb74312bb252fea9c40e7eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_06c0d6655faf41a2ace2372773746aee",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 433,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 433,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_16b9169fbff84e1e93b48f3b28823335"
     }
    },
    "51bf070093c44a6681639ae2fdb2e335": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_19992285488741579699790689a7fc97",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 433/433 [00:06&lt;00:00, 66.9B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c6989f206b6c4cbdb5c1c1fb3e7ac2ac"
     }
    },
    "06c0d6655faf41a2ace2372773746aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "16b9169fbff84e1e93b48f3b28823335": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "19992285488741579699790689a7fc97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "c6989f206b6c4cbdb5c1c1fb3e7ac2ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6bceb14ea46a4a3895c28d79a4585e99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_0ca9f3ea8b3c42fa8b86c38bafdde679",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_71595cbecf9241f8802c408b521362c4",
       "IPY_MODEL_136701faefcd4b099f4a12465159d076"
      ]
     }
    },
    "0ca9f3ea8b3c42fa8b86c38bafdde679": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "71595cbecf9241f8802c408b521362c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_806e889dba514f798ff1119cf2710908",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 440473133,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 440473133,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_b008247aa1cf415a98d782c1b9832c83"
     }
    },
    "136701faefcd4b099f4a12465159d076": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_9c04b67acf2846ab9946dd9c8b177e14",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 440M/440M [00:06&lt;00:00, 73.1MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6bbe3d657b8741f4987bc3da35b37e4c"
     }
    },
    "806e889dba514f798ff1119cf2710908": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "b008247aa1cf415a98d782c1b9832c83": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9c04b67acf2846ab9946dd9c8b177e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6bbe3d657b8741f4987bc3da35b37e4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "EinYpeWGGRx5"
   },
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcPjfkCju6V_"
   },
   "source": [
    "**Checking the Availability of GPU in the colab Notebook using cuda library and instructing it to use GPU for processing**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81tgqOMqGRyG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "961cca9c-e803-463d-809f-598bb29428d7"
   },
   "source": [
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print( torch.cuda.device_count())\n",
    "    print('Available:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "1\n",
      "Available: Tesla T4\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgQK1YjCvj6K"
   },
   "source": [
    "**Installing the required libraries required**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "romEHhWyGRyK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6863eea1-ee99-457a-d897-f9d985676f70"
   },
   "source": [
    "!pip install wget\n",
    "!pip install transformers"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=497aa6bf178618a183a8c7eb909e1fb78d00444b4b881235a76e98d26cdc359b\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Collecting transformers\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
      "\u001B[K     |████████████████████████████████| 1.4MB 8.4MB/s \n",
      "\u001B[?25hCollecting tokenizers==0.9.4\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9MB 51.9MB/s \n",
      "\u001B[?25hCollecting sacremoses\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001B[K     |████████████████████████████████| 890kB 46.0MB/s \n",
      "\u001B[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=9a8e532382936e282484e740adec07fd62a124b1da5e5a33f07891a8e8e97f87\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEOcvHhJvtbs"
   },
   "source": [
    "**Downloading the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dO56hpaDGRyN"
   },
   "source": [
    "url_train='https://groups.csail.mit.edu/sls/downloads/movie/engtrain.bio'\n",
    "url_test='https://groups.csail.mit.edu/sls/downloads/movie/engtest.bio'\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gjPc27BCGRyQ"
   },
   "source": [
    "import wget\n",
    "import os"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Hf97iYwGRyS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "3cf5fe28-fbce-49e9-807e-eab210007b31"
   },
   "source": [
    "wget.download(url_train)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'engtrain.bio'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uIjIrttBGRyX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "14012e22-3716-4173-cd15-c97ca38338ad"
   },
   "source": [
    "wget.download(url_test)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'engtest.bio'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo6xBZdevyJC"
   },
   "source": [
    "**Appending all the row lines from bio format file using csvreader() function**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2gSAx8Y5GRya"
   },
   "source": [
    "import csv\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "tokens = []\n",
    "token_labels = []\n",
    "unique_labels = set()\n",
    "\n",
    "with open(\"./engtrain.bio\", newline = '') as lines:                                                                                          \n",
    "  \n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    for line in line_reader:\n",
    "        \n",
    "        if line == []:\n",
    "\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "\n",
    "            unique_labels.add(line[0])\n",
    "\n",
    "            "
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS_qKmwL70x-"
   },
   "source": [
    "**Sentences Output**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WC65g2rytJ7",
    "outputId": "ad2b67fd-22d9-4d66-da72-b32609c3070b"
   },
   "source": [
    "  \n",
    "\n",
    "[  print(' '.join(sentences[i])) for i in range(10)]"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "what movies star bruce willis\n",
      "show me films with drew barrymore from the 1980s\n",
      "what movies starred both al pacino and robert deniro\n",
      "find me all of the movies that starred harold ramis and bill murray\n",
      "find me a movie with a quote about baseball in it\n",
      "what movies have mississippi in the title\n",
      "show me science fiction films directed by steven spielberg\n",
      "do you have any thrillers directed by sofia coppola\n",
      "what leonard cohen songs have been used in a movie\n",
      "show me films elvis films set in hawaii\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDg8hjB52u_J"
   },
   "source": [
    "**Preparing input text data for Feeding it into BERT model by converting and spilting the text into tokens and mapping the tokens using BertTokenizer functon**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOwSlC_23y0W",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6a041dc95d004cb58e9c6ab35a8f775e",
      "fbc255790ed645d2b9bbbe34a0f41fb4",
      "e0d1ca2f558d437d90ee539d4aa7d967",
      "4cb113d4cce749529b400becb7800e9a",
      "e6c77b6b00c8481d9373c1b232af6d70",
      "7c476f22442747cf9183adf6ec04e684",
      "a29928124a8b434d9dadd9145a9b700f",
      "955bbe594f494b0b8b5f8b0d680a7de8"
     ]
    },
    "outputId": "b66b8b23-7db7-4334-c93b-42d86596074e"
   },
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a041dc95d004cb58e9c6ab35a8f775e",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gha2W9-T4rVx",
    "outputId": "fc0f8e7d-4cd2-474c-bf74-9ca7b011ebc7"
   },
   "source": [
    "tokenizer.encode(sentences[1])"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lvqEe3-44YWL",
    "outputId": "029bb5b7-a1b5-4089-9a02-754c9680fdab"
   },
   "source": [
    "tokenizer.decode([101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102])"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] show me films with drew [UNK] from the 1980s [SEP]'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVU9xXifAJuM"
   },
   "source": [
    "**Calculating of length of each tokenized sentences**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FYUoces5_Df9"
   },
   "source": [
    "TokenLength=[len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZD9Ze4YRGRys",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1762dfdf-277e-41f2-db45-53c3f601eb23"
   },
   "source": [
    "print('Minimum  length: {:,} tokens'.format(min(TokenLength)))\n",
    "print('Maximum length: {:,} tokens'.format(max(TokenLength)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(TokenLength))))"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Minimum  length: 3 tokens\n",
      "Maximum length: 51 tokens\n",
      "Median length: 12 tokens\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv1-fXOPIF3P"
   },
   "source": [
    "**Now we must include Padding [PAD] token in the input so every tokens should be of same length. We have selected max length of PAD token to be 55 (as max is 51)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RvwHU9UKPDB",
    "outputId": "8db1b587-adfd-4293-812f-dccef092d6b5"
   },
   "source": [
    "#Sample Sentence\n",
    "SampleSentence=tokenizer.encode_plus(' '.join(sentences[1]), add_special_tokens = True,truncation = True,max_length = 50,padding = True,return_attention_mask = True, return_tensors = 'pt')\n",
    "SampleSentence"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CECUpOILCFg",
    "outputId": "11f57a41-648a-4add-93b0-136b3e809317"
   },
   "source": [
    "##input_ids\n",
    "print(\"\\nInput Ids:\",SampleSentence[\"input_ids\"])\n",
    "##attention_mask\n",
    "print(\"\\nAttention Mask:\",SampleSentence[\"attention_mask\"])"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Input Ids: tensor([[ 101, 2265, 2033, 3152, 2007, 3881, 6287, 5974, 2013, 1996, 3865,  102]])\n",
      "\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xh5TO6kyw7S"
   },
   "source": [
    "**Mapping Label**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7BbOt-rfdlQT"
   },
   "source": [
    "label_map = {}\n",
    "\n",
    "for (i, label) in enumerate(unique_labels):\n",
    "    \n",
    "    # Map it to its integer\n",
    "    label_map[label] = i"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3jld86Gg6lb"
   },
   "source": [
    "**Adding Attention Mask**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mqtli4ItGRy5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "11dba3c6-7d66-48a5-aaa7-332ce41733c7"
   },
   "source": [
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                 \n",
    "                        add_special_tokens = True,\n",
    "                        truncation = True,\n",
    "                        max_length = 55,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "        \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "print('Original: ', sentences[24])\n",
    "print('Token IDs:', input_ids[24])\n",
    "print('Masks:', attention_masks[24])"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Original:  ['find', 'the', 'movies', 'action', 'movies', 'directed', 'by', 'john', 'woo', 'from', 'the', '1990s']\n",
      "Token IDs: tensor([  101,  2424,  1996,  5691,  2895,  5691,  2856,  2011,  2198, 15854,\n",
      "         2013,  1996,  4134,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rEq3NzfJGRy8"
   },
   "source": [
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "null_label_id = -100\n",
    "\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    for token_id in sen:\n",
    "\n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    new_labels.append(padded_labels)\n"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J7Yb2HxHGRy-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7bdfe24-1df4-45fb-d395-b896c768a55b"
   },
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['what', 'movies', 'starred', 'both', 'al', 'pacino', 'and', 'robert', 'deniro']\n",
      "\n",
      "Labels:       ['O', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR', 'O', 'B-ACTOR', 'I-ACTOR']\n",
      "\n",
      "BERT Tokens:  ['what', 'movies', 'starred', 'both', 'al', 'pac', '##ino', 'and', 'robert', 'den', '##iro']\n",
      "\n",
      "Token IDs:    tensor([  101,  2054,  5691,  5652,  2119,  2632, 14397,  5740,  1998,  2728,\n",
      "         7939,  9711,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0])\n",
      "\n",
      "New Labels:   [-100, 13, 13, 13, 13, 7, 4, -100, 13, 7, 4, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJTXY7VC8EWz"
   },
   "source": [
    "**Convert the lists into PyTorch tensors using torch.stack**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "56ffz1wIGRzH"
   },
   "source": [
    "\n",
    "# Concatenates a sequence of tensors along a new dimension\n",
    "# [7,660  x  50].\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mEXnbx2qGRzP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bba222e3-d234-4296-b59f-e1d3ca1d6944"
   },
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "8,797 training samples\n",
      "  978 validation samples\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0_CkFFJmBlN"
   },
   "source": [
    "**Convert tensors into Batches for batch wise training and using RandomSampler for selecting the batch Randomly**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kl2f3rA6GRzU"
   },
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
    "\n",
    "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size   )"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qHvHBFmsRhnM"
   },
   "source": [],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yg7McKZmgim"
   },
   "source": [
    "**Using 12 Layer BERT Model for out task**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PYYvsMS2GRzb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f0f78f547a9a487f9fb75eb867a93884",
      "cff24be995c94fc089719a3cd60f1a72",
      "482813ec8bb74312bb252fea9c40e7eb",
      "51bf070093c44a6681639ae2fdb2e335",
      "06c0d6655faf41a2ace2372773746aee",
      "16b9169fbff84e1e93b48f3b28823335",
      "19992285488741579699790689a7fc97",
      "c6989f206b6c4cbdb5c1c1fb3e7ac2ac",
      "6bceb14ea46a4a3895c28d79a4585e99",
      "0ca9f3ea8b3c42fa8b86c38bafdde679",
      "71595cbecf9241f8802c408b521362c4",
      "136701faefcd4b099f4a12465159d076",
      "806e889dba514f798ff1119cf2710908",
      "b008247aa1cf415a98d782c1b9832c83",
      "9c04b67acf2846ab9946dd9c8b177e14",
      "6bbe3d657b8741f4987bc3da35b37e4c"
     ]
    },
    "outputId": "c5990ab9-80cb-4b63-9867-66f4148d8c09"
   },
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(label_map) + 1, output_attentions = False, output_hidden_states = False)\n",
    "\n",
    "\n",
    "model.cuda()"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f78f547a9a487f9fb75eb867a93884",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bceb14ea46a4a3895c28d79a4585e99",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VOE8XK4UGRzf"
   },
   "source": [
    "# Load the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon \n",
    "                )\n"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IaC7TvxnGRzh"
   },
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-VdS40_3GRzl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1af9a35-2e1b-42c1-caa1-cd2e509c9888"
   },
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "       \n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.43\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.18\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.13\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    275.\n",
      "  Batch    80  of    275.\n",
      "  Batch   120  of    275.\n",
      "  Batch   160  of    275.\n",
      "  Batch   200  of    275.\n",
      "  Batch   240  of    275.\n",
      "  Average training loss: 0.10\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PdTRwJEeGRzp",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "outputId": "615346a3-5502-4cc1-f79f-0f83f1fafeb1"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSsSXxx9oGPZ"
   },
   "source": [
    "**Preparing the Test dataset same as training dataset for predicting the results of our Trained model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w7_TcEDNKsWw"
   },
   "source": [
    "import csv\n",
    "\n",
    "# List of all sentences in the dataset.\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# Lists to store the current sentence.\n",
    "tokens = []\n",
    "token_labels = []\n",
    "unique_labels = set()\n",
    "\n",
    "with open(\"./engtest.bio\", newline = '') as lines:                                                                                          \n",
    "    \n",
    "    line_reader = csv.reader(lines, delimiter='\\t')\n",
    "    \n",
    "    for line in line_reader:\n",
    "        \n",
    "        if line == []:\n",
    "\n",
    "            sentences.append(tokens)\n",
    "            labels.append(token_labels)           \n",
    "    \n",
    "            tokens = []\n",
    "            token_labels = []        \n",
    "\n",
    "        else: \n",
    "\n",
    "            tokens.append(line[1])\n",
    "            token_labels.append(line[0])\n",
    "            unique_labels.add(line[0])"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rbtkP2ASKsgi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1cd49ef0-2c52-4214-a104-493588d82442"
   },
   "source": [
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(sent_str,add_special_tokens = True, max_length = 50,pad_to_max_length = True, return_attention_mask = True, return_tensors = 'pt')\n",
    "       \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Masks:', attention_masks[0])"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Original:  ['are', 'there', 'any', 'good', 'romantic', 'comedies', 'out', 'right', 'now']\n",
      "Token IDs: tensor([  101,  2024,  2045,  2151,  2204,  6298, 22092,  2041,  2157,  2085,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "93XGGErfKsjv"
   },
   "source": [
    "new_labels = []\n",
    "\n",
    "null_label_id = -100\n",
    "\n",
    "for (sen, orig_labels) in zip(input_ids, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "\n",
    "    orig_labels_i = 0 \n",
    "\n",
    "    for token_id in sen:\n",
    "        \n",
    "        token_id = token_id.numpy().item()\n",
    "\n",
    "        if (token_id == tokenizer.pad_token_id) or \\\n",
    "            (token_id == tokenizer.cls_token_id) or \\\n",
    "            (token_id == tokenizer.sep_token_id):\n",
    "            \n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "        else:\n",
    "            \n",
    "\n",
    "            label_str = orig_labels[orig_labels_i]\n",
    "\n",
    "            padded_labels.append(label_map[label_str])\n",
    "\n",
    "            orig_labels_i += 1\n",
    "\n",
    "    assert(len(sen) == len(padded_labels))    \n",
    "\n",
    "    new_labels.append(padded_labels)\n"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JTGNzTeXKsmz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d851cb2f-29db-442d-b264-fea7a7380a07"
   },
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nMask:        ', attention_masks[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:     ['list', 'the', 'five', 'star', 'rated', 'movies', 'starring', 'mel', 'gibson']\n",
      "\n",
      "Labels:       ['O', 'O', 'B-RATINGS_AVERAGE', 'I-RATINGS_AVERAGE', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR']\n",
      "\n",
      "BERT Tokens:  ['list', 'the', 'five', 'star', 'rated', 'movies', 'starring', 'mel', 'gibson']\n",
      "\n",
      "Token IDs:    tensor([  101,  2862,  1996,  2274,  2732,  6758,  5691,  4626, 11463,  9406,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "\n",
      "Mask:         tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "\n",
      "New Labels:   [-100, 13, 13, 19, 1, 13, 13, 13, 7, 4, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a7SzPapJLOyg"
   },
   "source": [
    "\n",
    "pt_input_ids = torch.stack(input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.long)"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NppBuk1QLdiO"
   },
   "source": [
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkNAIgwXo4DZ"
   },
   "source": [
    "**Prediction on test set**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "785gLPxdLO1S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99c04c58-39be-4e78-8492-52211b376b76"
   },
   "source": [
    "\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,443 test sentences...\n",
      "    DONE.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zE4mSq9TLO4F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ee07be09-03d6-48db-d086-6bc557c9ded3"
   },
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "After flattening the batches, the predictions have shape:\n",
      "     (2443, 50, 26)\n",
      "\n",
      "After choosing the highest scoring label for each token:\n",
      "     (2443, 50)\n",
      "\n",
      "After flattening the sentences, we have predictions:\n",
      "     (122150,)\n",
      "and ground truth:\n",
      "     (122150,)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uAdgtvbvLope",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1fc8625f-de18-4368-d5e8-f6a176090c31"
   },
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))\n"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Before filtering out `null` tokens, length = 122,150\n",
      " After filtering out `null` tokens, length = 24,686\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q-awFd4kLosC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1d384a4-e6ff-497b-f7c3-8665f94cbb40"
   },
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(real_token_labels, real_token_predictions, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))"
   ],
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "F1 score: 94.45%\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evga9CGCeSG5"
   },
   "source": [
    "# **Testing the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cz7xJngdzlc",
    "outputId": "c74b8315-5eb0-4d44-f0ff-2670b4e5e6e0"
   },
   "source": [
    "test_sentence = input (\"Enter number :\") "
   ],
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Enter number :Characterized by its use of Technicolor, fantasy storytelling, musical score, and memorable characters, the film has become an American pop culture icon. It was nominated for six Academy Awards, including Best Picture, but lost to Gone with the Wind, also directed by Fleming.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUXjwTfovbcy"
   },
   "source": [
    "## ***Checking the Results*** "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XdHIKtw0bHgx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "outputId": "2852982c-5344-4722-ace3-cb3e801cbde8"
   },
   "source": [
    "\n",
    "#Encoding and convert the sentences into tensors\n",
    "sample_sentence = tokenizer.encode(test_sentence)\n",
    "sample_input_ids = torch.tensor([sample_sentence]).cuda()\n",
    "\n",
    "#Predicting the test data set using model() function\n",
    "with torch.no_grad():\n",
    "    output = model(sample_input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "#Function which retrieves key value for our Label Dictionary\n",
    "def get_key(val):\n",
    "    for key, value in label_map.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "#Tokenize  \n",
    "tokens = tokenizer.convert_ids_to_tokens(sample_input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_label = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_label.append(get_key(label_idx))\n",
    "        new_tokens.append(token)\n",
    "\n",
    "#Appending Tokens and Labels\n",
    "movie_token=[]\n",
    "movie_label=[]\n",
    "for token, label in zip(new_tokens, new_label):\n",
    "    movie_token.append(token) \n",
    "    movie_label.append(label)\n",
    "\n",
    "df=pd.DataFrame({\"Token\":movie_token,\"Movie_Label\":movie_label})\n",
    "df.T"
   ],
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>characterized</td>\n",
       "      <td>by</td>\n",
       "      <td>its</td>\n",
       "      <td>use</td>\n",
       "      <td>of</td>\n",
       "      <td>technicolor</td>\n",
       "      <td>,</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>storytelling</td>\n",
       "      <td>,</td>\n",
       "      <td>musical</td>\n",
       "      <td>score</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>memorable</td>\n",
       "      <td>characters</td>\n",
       "      <td>,</td>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>has</td>\n",
       "      <td>become</td>\n",
       "      <td>an</td>\n",
       "      <td>american</td>\n",
       "      <td>pop</td>\n",
       "      <td>culture</td>\n",
       "      <td>icon</td>\n",
       "      <td>.</td>\n",
       "      <td>it</td>\n",
       "      <td>was</td>\n",
       "      <td>nominated</td>\n",
       "      <td>for</td>\n",
       "      <td>six</td>\n",
       "      <td>academy</td>\n",
       "      <td>awards</td>\n",
       "      <td>,</td>\n",
       "      <td>including</td>\n",
       "      <td>best</td>\n",
       "      <td>picture</td>\n",
       "      <td>,</td>\n",
       "      <td>but</td>\n",
       "      <td>lost</td>\n",
       "      <td>to</td>\n",
       "      <td>gone</td>\n",
       "      <td>with</td>\n",
       "      <td>the</td>\n",
       "      <td>wind</td>\n",
       "      <td>,</td>\n",
       "      <td>also</td>\n",
       "      <td>directed</td>\n",
       "      <td>by</td>\n",
       "      <td>fleming</td>\n",
       "      <td>.</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie_Label</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-GENRE</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-GENRE</td>\n",
       "      <td>I-GENRE</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-RATINGS_AVERAGE</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-TITLE</td>\n",
       "      <td>I-TITLE</td>\n",
       "      <td>I-TITLE</td>\n",
       "      <td>I-TITLE</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-DIRECTOR</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0              1   2    3   ...  50          51 52     53\n",
       "Token        [CLS]  characterized  by  its  ...  by     fleming  .  [SEP]\n",
       "Movie_Label      O              O   O    O  ...   O  I-DIRECTOR  O      O\n",
       "\n",
       "[2 rows x 54 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 65
    }
   ]
  }
 ]
}
